---
isDraft: true
title: The Question is the Answer
subtitle: Using LLMs as Interviewers
description: ""
image:
    src: /images/the-question-is-the-answer-cover.webp
    alt: "An abstract digital illustration of a man holding a clipboard and a pencil."
    caption: "Generated by DALL-E"
publishDate: "2024-07-31"
tags:
- llm
- rag
- documentation
- knowledge-base
recommended: []
---

It seems like most of the current use cases for LLMs have to do with summarization and RAG. Both involve an LLM answering questions, for a user, about a piece of text. Either "summarize the following..." or "anser question X based on Y documents."

I believe that by flipping that paradigm – using LLMs to generate questions for a user to answer – there would be a huge potential value unlock.


## Setting the Scene

I think we can all agree, good documentation is vital. Maybe you're documenting your code, maybe you're documenting a business process, or maybe you're taking scratch notes to remember what you just did. It's vital for other people on your team. It's vital when you leave your company, for the next person who replaces you. It's even just for you in 3 months, when you forget how something works.

The act of documenting can be helpful, too. The writing process can help you solidify your thought process and can help commit things to memory.

But, all that being said, good documentation takes time – time to make, time to organize, and time to maintain. Sometimes it's worth it and sometimes it may not be. And what if we could use LLMs to help bridge that gap.


## Talk to Me Goose

<figure>
  <img src="/images/twin-peaks-recorder.webp" alt="Agent dale cooper is driving a car while recording a note on a hand-held recorder." />
  <figcaption>
    A still from <a href="https://en.wikipedia.org/wiki/Twin_Peaks">Twin Peaks</a> where Agent Dale Cooper is recording a note for his secretary, Diane.
  </figcaption>
</figure>

Now imagine – rather than writing up, organizing, and distributing documentation – you just had to record quick, extemporaneous notes.

They don't have to be recorded, they could also be written, but the key is that they're quick. You don't have to break out of the flow of your work.

This tool could have access to some context about you (e.g. your role, your projects, your team, your calendar, etc.), it could also have context about what you're doing (e.g. "you're currently working in an IDE, on repo X, and you have file Y open"), and it could have the context of previous notes you've created. Using that information, it could generate a small update / note / log-entry which could be queried later (e.g. an auto-generated update for your stand-up) or used to update other documentation (I'm picturing something like an event-sourced real-time database – where these notes are the events and the documentation is generated by replaying these updates).

If you think this sounds like [Microsoft Recall](https://www.theverge.com/2024/6/20/24182350/microsoft-windows-recall-launch-on-arm), I get it, but I think there's a key difference. The goal is not to be able to look back at screenshots of all the websites you browsed in the past year. The artifact being stored is the note. At most the contextual data would help enrich the model's understanding in the moment. So you could say something like "this email" or "the error on this line" and the model could understand what you mean.


## The Five(-ish) Whys

<figure>
  <img src="/images/why-meme.jpg" alt='A curious taxidermied cat diptych. Aka the "Persian Cat Room Guardian" meme.' />
  <figcaption>
    The 
    <a href="https://knowyourmeme.com/memes/persian-cat-room-guardian">Persian Cat Room Guardian</a>
    meme.
  </figcaption>
</figure>

So far we've just discussed a context-aware note-recorder. What about the interview side of things?

This is where I think LLMs have the potential to shine. Up to this point we've been relying on LLMs to answer our questions, but what if instead they asked the questions?

Back to our examples, imagine you just fixed a bug in your codebase and you're logging a note. You start recording. You highlight a line of text and explain that there was an error in this line of code. Your AI-note-taker can *see* the repo you're working on, the file your in, and the line you have highlighted. But there's missing information. What is the error? How did you fix it? What are the implications? Etc.

What if, rather than a static note-taker, it could be an active participant? It could review the information you've given it, look for gaps in its knowledge, and generate a list of questions to fill in those gaps. You answer the questions. It updates its understanding. And the process can continue until it's happy or until you feel like it has enough information.

Alternatively, the process doesn't have to be triggered by your quick status update. Instead, you could go to the bot and let it ask you a bunch of questions. Imagine you want a more in-depth understanding of a process. You could be "interviewed" by a bot. The process might be similar but wheras in the previous example, you don't want to break your flow and the bot just wants to ask a couple of follow up questions for clarity, in this case it's goal is to build out a more comprehensive, structured piece of documentation.


## That's a Dumb Question

<figure>
  <img src="/images/are-we-there-yet.webp" alt='A screen-grab from the Simpsons, with the family in the car and bart asking "are we there yet?".' />
  <figcaption></figcaption>
</figure>

> What could go wrong?

- Am I just going to be subjected to a million bad questions?
  - Maybe?
- So you're just automating me away?
  - That would be a bit of a stretch
- Isn't that just [Recall](https://www.theverge.com/2024/6/20/24182350/microsoft-windows-recall-launch-on-arm)?
  - Not really. Different goals. See above.

At this point it may sound like I'm suggesting we turn loose a pestersome, AI-enhanced noodge. I'm aware that there's a lot about this that could go wrong.

Let's go over just a couple possible issues.

> Am I just going to be subjected to an infinite stream of bad questions?

Honestly, maybe. But 

> Is this just going to be used to automate away my job?



> Isn't that just Recall?


## Conclusion

> TK

Get some time back. Write more notes. Let the AI transcribe it. If it doesn't understand you, it should ask you some clarifying questions.

Does it work? I'm not sure. But it could gracefully degrade to audio recordings.

What's the alternative? Spending lots of time documenting? Or (more likely) not documenting things?

I'm not saying this is a replacement for good manual documentation but I think it could be a good suplement.

