---
isDraft: true
title: The Question is the Answer
subtitle: Using LLMs as Interviewers
description: ""
image:
    src: /images/the-question-is-the-answer-cover.webp
    alt: "An abstract digital illustration of a man holding a clipboard and a pencil."
    caption: "Generated by DALL-E"
publishDate: "2024-07-31"
tags:
- llm
- rag
- documentation
- knowledge-base
recommended: []
---

# Notes

To expand on my idea a bit, currently I think most of the uses for LLMs are around answering questions (e.g. via RAG over a set of documents or a dataset). In this case, people have to curate documents that will make up the knowledge base for the LLMs. What if instead (or in addition), it was the job of an LLM to generate thoughtful questions that would help augment that knowledge base?

We're also getting to a point where data is extremely valuable. People training LLMs are running low on good quality data on which to train.

There are whole industries – e.g. consultancies like McKinsey – who spend significant time and resources on "information gathering." I think that's something an LLM could be doing instead.

LLMs could A) perform information gathering by asking thoughtful questions and B) work to categorize and curate that dataset / knowledge base.

I think most (if not all) companies have a good deal of valuable information that isn't codified anywhere – known as "tacit knowledge." That can lead to problems. Say for example Alice has to perform a business process like rotating credentials once a quarter but this is tacit knowledge and not written down anywhere. Let's think through some potential issues that could arise:
- Alice could forget to do it one quarter
- Alice could leave the company and no one knows to take over for him
- Bob might be doing the same thing without realizing it, wasting time and effort
- Bob might be doing something else that conflicts with Alice's work, without realizing it

Currently, the solution to this is pushing people to document their work and to communicate. That is, of course, not a bad thing but it requires a balance. You don't want people over-communicating – at which point there's too much noise and Alice might not see an email from Bob saying he's also rotating credentials – and you also don't want people spending too much time documenting. Documentation needs to be good – which is a skill that isn't a given – and good documentation takes time.

What if we could use an LLM to "interview" Alice (as well as Bob and everyone else), with the goal of discovering any tacit knowledge, curate the results, and flag any potential issues (e.g. "Alice quit and now no one is doing X" or "Alice and Bob appear to both be repeating the same effort").

As for technology, I think that's more of an implementation detail, at least for now.

# Outline

- Intro
  - The main use for LLMs now is RAG
  - We maintain knowledge bases which they reference to generate answers
- Interview with an LLM
  - We could use LLMs to *interview* people about what they're doing to document as they go
  - Essentially you would just brain dump about what you're doing from time-to-time and an LLM would process the results
  - People like to talk. Let them.
- What could it do?
  - It can help remind you what you're working on
  - Auto-generate your stand-up notes
  - Auto-generate your brag document
  - (Alice + Bob examples)
- Examples in the Wild
  - Is this just Rewind / Microsoft Recall
  - Perplexity
- What could go wrong?
  - It could get it wrong (bad summaries)
  - People could not want to use it ("You're just going to try to automate me away")
  - It could be too intrusive
  - It could be a security hole ("cool now all our sensitive info is in one place!")
  - It could be too much of a half-measure ("in order for it to *really* work we'd need to do more than we want to")
- Conclusion

# Draft

It seems like most of the current use cases for LLMs have to do with summarization and RAG. Both involve an LLM answering questions, for a user, about a piece of text. Either "summarize the following..." or "anser question X based on Y documents."

I believe that by flipping that paradigm – using LLMs to generate questions for a user to answer – there would be a huge potential value unlock.


## Setting the Scene

I think we can all agree, good documentation is vital. Maybe you're documenting your code, maybe you're documenting a business process, or maybe you're taking scratch notes to remember what you just did. It's vital for other people on your team. It's vital when you leave your company, for the next person who replaces you. It's even just for you in 3 months, when you forget how something works.

The act of documenting can be helpful, too. The writing process can help you solidify your thought process and can help commit things to memory.

But, all that being said, good documentation takes time – time to make, time to organize, and time to maintain. Sometimes it's worth it and sometimes it may not be. And what if we could use LLMs to help bridge that gap.


## Talk to Me Goose

<figure>
  <img src="/images/twin-peaks-recorder.webp" alt="Agent dale cooper is driving a car while recording a note on a hand-held recorder." />
  <figcaption>
    A still from <a href="https://en.wikipedia.org/wiki/Twin_Peaks">Twin Peaks</a> where Agent Dale Cooper is recording a note for his secretary, Diane.
  </figcaption>
</figure>

Now imagine – rather than writing up, organizing, and distributing documentation – you just had to record quick, extemporaneous notes.

They don't have to be recorded, they could also be written, but the key is that they're quick. You don't have to break out of the flow of your work.

This tool could have access to some context about you (e.g. your role, your projects, your team, your calendar, etc.), it could also have context about what you're doing (e.g. "you're currently working in an IDE, on repo X, and you have file Y open"), and it could have the context of previous notes you've created. Using that information, it could generate a small update / note / log-entry which could be queried later (e.g. an auto-generated update for your stand-up) or used to update other documentation (I'm picturing something like an event-sourced real-time database – where these notes are the events and the documentation is generated by replaying these updates).

If you think this sounds like [Microsoft Recall](https://www.theverge.com/2024/6/20/24182350/microsoft-windows-recall-launch-on-arm), I get it, but I think there's a key difference. The goal is not to be able to look back at screenshots of all the websites you browsed in the past year. The artifact being stored is the note. At most the contextual data would help enrich the model's understanding in the moment. So you could say something like "this email" or "the error on this line" and the model could understand what you mean.


## The Five(-ish) Whys

<figure>
  <img src="/images/why-meme.jpg" alt='A curious taxidermied cat diptych. Aka the "Persian Cat Room Guardian" meme.' />
  <figcaption>
    The 
    <a href="https://knowyourmeme.com/memes/persian-cat-room-guardian">Persian Cat Room Guardian</a>
    meme.
  </figcaption>
</figure>

So far we've just discussed a context-aware note-recorder. What about the interview side of things?

This is where I think LLMs have the potential to shine. Up to this point we've been relying on LLMs to answer our questions, but what if instead they asked the questions?

Back to our examples, imagine you just fixed a bug in your codebase and you're logging a note. You start recording. You highlight a line of text and explain that there was an error in this line of code. Your AI-note-taker can *see* the repo you're working on, the file your in, and the line you have highlighted. But there's missing information. What is the error? How did you fix it? What are the implications? Etc.

What if, rather than a static note-taker, it could be an active participant? It could review the information you've given it, look for gaps in its knowledge, and generate a list of questions to fill in those gaps. You answer the questions. It updates its understanding. And the process can continue until it's happy or until you feel like it has enough information.

Alternatively, the process doesn't have to be triggered by your quick status update. Instead, you could go to the bot and let it ask you a bunch of questions. Imagine you want a more in-depth understanding of a process. You could be "interviewed" by a bot. The process might be similar but wheras in the previous example, you don't want to break your flow and the bot just wants to ask a couple of follow up questions for clarity, in this case it's goal is to build out a more comprehensive, structured piece of documentation.


## Does it Work?

> I don't know

```
LLM: Hi! I’m excited to learn more about what you’re working on. Could you give me a quick overview of your current project?

User: Hey! I’m working on optimizing our client-side caching strategy to improve our web app’s performance and reduce server load. It’s something we’ve needed to tackle for a while.

LLM: That sounds interesting! How are you planning to decide which parts of the data should be cached?

User: We’re focusing on caching static data that doesn’t change often, like user profiles and product details. Dynamic data will still be fetched live from the server to ensure accuracy.

LLM: Great approach! What tools or libraries are you using to implement this caching strategy?

User: We’re using a combination of IndexedDB for storing larger data sets and the browser’s local storage for smaller, quick-access data. Both are pretty straightforward and integrate well with our existing setup.

LLM: Nice! How do you plan to handle cache invalidation to keep everything up to date?

User: We’re setting up a time-based expiration for most cached items. Additionally, we’ll have triggers to clear the cache when specific server-side events occur, like updates to user settings.

User: /done

LLM: Got it, thanks for sharing all that! If you need help with anything else or have more updates, feel free to let me know. Good luck with the project!
```


## That's a Dumb Question

> What could go wrong?

- Isn't that just [Recall](https://www.theverge.com/2024/6/20/24182350/microsoft-windows-recall-launch-on-arm)?
- So you're just automating me away?
- Am I just going to be subjected to a million bad questions?


## Conclusion

> TK

Get some time back. Write more notes. Let the AI transcribe it. If it doesn't understand you, it should ask you some clarifying questions.

Does it work? I'm not sure. But it could gracefully degrade to audio recordings.

What's the alternative? Spending lots of time documenting? Or (more likely) not documenting things?

I'm not saying this is a replacement for good manual documentation but I think it could be a good suplement.

