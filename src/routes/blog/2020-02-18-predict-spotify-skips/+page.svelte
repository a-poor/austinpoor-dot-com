<script lang="ts">
  import BlogBody from '$lib/BlogBody.svelte';
  import BlogHeader from '$lib/BlogHeader.svelte';
  import BlogImage from '$lib/BlogImage.svelte';
  import BlogHeading1 from '$lib/BlogHeading1.svelte';
  import BlogHeading2 from '$lib/BlogHeading2.svelte';
  import BlogBlockQuote from '$lib/BlogBlockQuote.svelte';
</script>

<svelte:head>
  <title>Predicting Spotify Track Skips | Austin's Blog</title>

  <meta name="description" content="Working on the Spotify Sequential Skip Prediction Challenge" />
  <meta name="keywords" content="spotify, python, data-science, machine-learning, bootcamp" />
  <meta name="robots" content="index, follow" />
  <meta name="author" content="Austin Poor" />
  
  <meta property="og:title" content="Predicting Spotify Track Skips" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://austinpoor.com/blog/2020-02-18-predict-spotify-skips" />
  <meta property="og:image" content="https://austinpoor.com/propic-square.jpg" />
  <meta property="article:published_time" content="2020-02-18" />
  <meta property="article:author" content="Austin Poor" />
  <meta property="article:tag" content="spotify, python, data-science, machine-learning, bootcamp" />
</svelte:head>

<BlogBody>
  <BlogHeader 
    title="Predicting Spotify Track Skips"
    subtitle="Working on the Spotify Sequential Skip Prediction Challenge"
    publicationDate="2020-02-18"
  />

  <BlogImage 
    src="/spotify-skip-cover.webp"
    alt="Screenshots from the Spotify desktop app"
    desc="(Screenshots from the Spotify desktop app)"
  />

  <BlogHeading1>Introduction</BlogHeading1>

  <p>
    I worked on a slightly simplified version of the <span class="italic">Spotify Sequential Skip Prediction 
    Challenge</span> [1] as my 3rd project for the Metis Data Science Bootcamp.
  </p>

  <p>
    Spotify — as I'm sure you're aware — is a streaming service whose business model is centered around 
    delivering song recommendations to users in order to keep them using their app.
  </p>

  <BlogBlockQuote>
    Spotify has over <span class="not-italic">190 million</span> active users interacting with over 
    <span class="not-italic">40 million</span> tracks.
  </BlogBlockQuote>

  <p>
    The goal of the challenge is to predict the likelihood of a user skipping any given song during 
    a listening session.
  </p>

  <BlogHeading1>Methodology</BlogHeading1>

  <BlogHeading2>The Data</BlogHeading2>

  <p>
    For the competition, Spotify supplied two main sets of information. One table has information 
    about user listening sessions. For example:
  </p>

  <ul class="list-disc list-inside">
    <li>Session ID</li>
    <li>Position in the session</li>
    <li>Track ID</li>
    <li>If the track was skipped or not</li>
    <li>Other session metadata</li>
  </ul>

  <p>
    Note that the user sessions were all between 10 and 20 tracks long and didn't include any 
    identifiable information about the users.
  </p>

  <p>
    The second table has metadata about the tracks (corresponding to the <code>track_id</code> feature from 
    the session table), such as:
  </p>

  <ul class="list-disc list-inside">
    <li>Track duration</li>
    <li>Track popularity in the US</li>
    <li>Release year</li>
  </ul>

  <p>
    As well as some extra features, generated by Spotify, to describe the songs, such as:
  </p>

  <ul class="list-disc list-inside">
    <li class="italic">acousticness</li>
    <li class="italic">beat strength</li>
    <li class="italic">bounciness</li>
    <li class="italic">danceability</li>
  </ul>

  <p>
    The dataset also includes a set of 8 “acoustic vectors” for each track which are latent encodings 
    that Spotify has generated for each track.
  </p>

  <p>
    For licensing reasons, Spotify anonymize the track information, so there aren't any data on things 
    like track name, artist, album, or genre.
  </p>

  <p>
    The targets in the provided dataset — whether or not the track was skipped — are balanced with about 
    51.7% of the tracks being skipped. So there was no need to adjust the class balances for training.
  </p>

  <p>
    There was a surplus of data so I worked with a subset of about 100k rows from the session table and 
    the corresponding rows from the track table, which I loaded into a Postgres database hosted on an AWS 
    EC2 instance. The database schema is shown below:
  </p>

  <BlogImage 
    src="/spotify-skip-data-schema.webp"
    alt="Schema for the spotify skip dataset."
    desc="Schema for Spotify Skip Data"
  />

  <p>
    To get a sense of what a single session might look like, the following image shows a plot of a single 
    user session as it relates to one of the features — “track loudness”, a Spotify descriptor of the song's 
    characteristics, not “volume” in the traditional sense — where the color indicates which tracks were 
    skipped and not skipped.
  </p>

  <BlogImage 
    src="/spotify-single-session-skips-vs-loudness.webp"
    alt="Graph of a Single Session's Track-Skips vs Track-Loudness"
    desc="Single Session's Track-Skips vs Track-Loudness"
  />
  
  <p>
    While not meaningful by itself, this illustrates how each session an be plotted against the song attributes. 
    In this example, the user only listened to two of the first 11 tracks, and then listened to all of the 
    remaining 9 tracks, as the loudness value decreased.
  </p>

  <p>
    Further, in order to get a better sense of the overall distribution track attributes, I've plotted the 
    distribution of a small subset of the features and highlighted where three different songs fall in the 
    distribution (using data from the Spotify API). The three songs, from three different genres, are:
  </p>

  <ul class="list-disc list-inside">
    <li>
      Willie Nelson's "<a class="underline" href="https://open.spotify.com/track/7jWbXvrgdbkajU8L28ahn5?si=SjrUPcJ8T_OZE9SY6qhF7w">Highwayman</a>" (Country)
    </li>
    <li>
      Wu-Tang Clan's “<a class="underline" href="https://open.spotify.com/track/1Sgj10byiGzPpI2IrXSFEn?si=idphDdbRTduLWbG1G84KjQ">Protect Ya Neck</a>” (Hip-Hop/R&B)
    </li>
    <li>
      John Coltrane's “<a class="underline" href="https://open.spotify.com/track/5z8eOnPiOC22EYpniAX3Qg?si=K55hpE-6TjSfgf_6k0zJWA">Blue World</a>” (Jazz)
    </li>
  </ul>

  <p>
    Below are the attribute distribution plots for the attributes “energy”, “loudness”, “danceability”, and “acousticness”:
  </p>
  
  <BlogImage 
    src="/spotify-track-features-applied-to-example-songs.webp"
    alt="Plot of a distribution of a subset of track features with 3 songs plotted for reference"
    desc="Distribution of a Subset of Track Features with 3 Songs Plotted for Reference"
  />

  <BlogHeading2>Feature Engineering</BlogHeading2>

  <p>
    This data is inherently sequential. The model's skip-prediction for any given song will be based on the 
    songs that were skipped earlier in the user listening session. Therefore, in order for my model to account 
    for that, I added a group of features that represent the previous tracks' audio features as well as whether 
    or not those tracks were skipped.
  </p>

  <p class="italic">
    Side-Note: I also tried an alternative approach where I added two sets of features corresponding to the 
    average track feature information for previous tracks that were skipped and tracks that were not skipped, 
    respectively, but found that it took longer to compute, added twice the number of features, and didn't 
    improve model performance.
  </p>

  <BlogHeading2>Model Selection</BlogHeading2>

  <p>
    The target metric is accuracy, per competition guidelines.
  </p>

  <p>
    I started by baselining with a Logistic Regression model but found that it had poor accuracy. So from there, 
    I moved on to tree-based models which would be less interpretable but would be able to automatically handle 
    complex feature interactions.
  </p>
  
  <BlogHeading1>Results</BlogHeading1>

  <BlogImage 
    src="/spotify-roc-logistic-regression-vs-lightgbm.webp"
    alt="ROC Curve Comparing Model Performance for Logistic Regression and LightGBM Models"
    desc="ROC Curve Comparing Model Performance for Logistic Regression and LightGBM Models"
  />

  <p>
    My best model's final test accuracy was <span class="font-semibold">0.73</span>, using LightGBM's 
    <code>LGBMClassifier</code> model, which is fairly good given the problem but with room for improvement.
  </p>

  <p>
    After training the model, I analyzed the errors, looking for areas to improve the model, but didn't find 
    any clear trends in the residuals.
  </p>
  
  <BlogHeading1>Conclusions</BlogHeading1>

  <BlogImage 
    src="/spotify-lightgbm-feature-importance-graph.webp"
    alt="Final LightGBM Model's Relative Feature Importance Ranking"
    desc="Final LightGBM Model's Relative Feature Importance Ranking"
  />

  <p>
    This figure shows the final model's ranking of the top 10 features by relative importance. The model ranked 
    <span class="italic">track popularity</span> as the most important feature, followed by the 
    <span class="italic">track duration</span>, and then the <span class="italic">previous track's popularity</span>. 
    The ranking seems to generally make sense and isn't picking up on anything too surprising, other than possibly the 
    fact that <span class="italic">track popularity</span> is ranked much higher than the next most important feature. 
    Interestingly, though, this graph (as well as the graph of the full ranking which can be seen below, in the appendix) 
    shows that, in a few cases, the model seems to be comparing features for the current track and the previous track. 
    Some examples include <span class="italic">popularity</span>, <span class="italic">duration</span>, and 
    <span class="italic">loudness</span>.
  </p>

  <p>
    Again, the model performance is reasonable, with an accuracy of 0.73 compared to a completely naive model 
    (always predicting that the track will be skipped) that would have an accuracy of 0.51, but still with plenty of 
    room for improvement.
  </p>
  
  <BlogHeading1>Future Work</BlogHeading1>

  <p>
    Moving forward, a few areas for continued work include:
  </p>

  <ul class="list-disc list-inside">
    <li>Add unsupervised learning to cluster songs based on track features and possibly generate “pseudo-genres”</li>
    <li>Make predictions using a Recurrent Neural Network, that could more naturally handle <span class="italic">sequential</span> track information</li>
    <li>Supplement the dataset with more data from Spotify's API (e.x. genre information)</li>
    <li>Create a Flask app that uses D3 to visualize model predictions and allow the user to interactively explore the dataset</li>
  </ul>

  <p>
    Thanks for reading and I'd love to hear your thoughts!
  </p>
  
  <BlogHeading1>Appendix</BlogHeading1>

  <ul class="list-disc list-inside">
    <li><span class="italic">Acousticness</span>: Likelihood a track is acoustic</li>
    <li><span class="italic">Danceability</span>: Describes how suitable a track is for dancing</li>
    <li><span class="italic">Energy</span>: Measure of a track's intensity</li>
    <li><span class="italic">Valence</span>: Level of “positiveness” conveyed by a track</li>
    <li><span class="italic">Speachiness</span>: Detects the presence of spoken words</li>
  </ul>

  <BlogHeading2>Feature Subset Description</BlogHeading2>
  
  <BlogHeading2>Full Model Feature Importance Rank</BlogHeading2>

  <BlogImage 
    src="/spotify-full-model-feature-importance-graph.webp"
    alt="Full Model Feature Importance Ranking"
  />
  
  <BlogHeading2>Track “Acoustic Vector” Correlation Matrix</BlogHeading2>

  <BlogImage 
    src="/spotify-acoustic-vector-correlation-matrix.webp"
    alt="Track's “Acoustic Vector” Feature Correlation Matrix"
  />
  
  <BlogHeading1>Citations</BlogHeading1>

  <p>
    <a class="underline" href="https://www.crowdai.org/challenges/spotify-sequential-skip-prediction-challenge">Here's</a>
    a link to the challenge site (which has more information on the dataset and the challenge rules).
  </p>

  <p>
    [1] B. Brost, R. Mehrotra, and T. Jehan, The Music Streaming Sessions Dataset (2019), Proceedings of the 2019 Web Conference
  </p>

</BlogBody>